import glob
import numpy as np
from skimage.io import imread
from os import walk
from skimage.color import rgb2hsv, rgb2gray
from skimage.filters import threshold_otsu

def ladeBilder(anztr,anztest):
    # labels = ["Apple_Green", "Apple_Red", "Banana", "Carambola", "Guava", "Kiwi", "Mango", "Muskmelon", "Orange", "Peach", "Pear", "Persimmon", "Pitaya", "Plum", "Pomegranate", "Tomatoes"]
    _, labels, _ = walk("./DataSet").__next__()

    # Pfadstrings der Trainingsdaten

    trStrings = []
    for label in labels:
        trStrings += glob.glob("./DataSet/" + label + "/Training/*.png")

    # Labels der Trainingsdaten

    trLabels = []
    for i in range(len(labels)):
        trLabels += [i] * anztr

    # Labels der Testdaten
    testLabels = []
    for i in range(len(labels)):
        testLabels += [i] * anztest

    # Pfadstrings der Testdaten

    testStrings = []
    for label in labels:
        testStrings += glob.glob("./DataSet/" + label + "/Test/*.png")

    # Einlesen der Bilder

    trImgs = []
    for path in trStrings:
       trImgs.append(imread(path))

    testImgs = []
    for path in testStrings:
        testImgs.append(imread(path))

    return trLabels,testLabels,trImgs,testImgs

def erstelleVektorRelevanterPixel(img, mask):
    vektor = []
    for x in range(img.shape[0]):
        for y in range(img.shape[1]):
            if(mask[x,y] != 0):
                vektor.append(img[x,y])
    return np.asarray(vektor)

def erstelleVektorRelevanterPixelOhneMinimum(img, mask):
    vektorOM = []
    imgV = rgb2hsv(img)[:, :, 2]  #Get value in HSV

    for x in range(img.shape[0]):
        for y in range(img.shape[1]):
            if(mask[x,y] != 0):
                a = imgV[x, y]
                if(a > 0.05):
                    vektorOM.append(img[x,y])
    return np.asarray(vektorOM)

def erstelleVektoren(imgs, masks):
    vektoren = []
    for i in range(len(imgs)):
        vektoren.append(erstelleVektorRelevanterPixel(imgs[i],masks[i]))
    return np.asarray(vektoren)

def erstelleVektorenOhneMinimum(imgs, masks):
    vektorenOM = []
    for i in range(len(imgs)):
        vektorenOM.append(erstelleVektorRelevanterPixelOhneMinimum(imgs[i],masks[i]))
    return np.asarray(vektorenOM)

def createSMasks(imgs):
    masks = []
    for img in imgs:
        imgS = rgb2hsv(img)[:, :, 1]
        masks.append(imgS > threshold_otsu(imgS))
    return masks

def MaskiereBilder (img,mask):
    crop = []
    for i in range(len(img)):
        ausgeschnitten  = img[i] * mask[i][ :, :, None]
        crop.append(ausgeschnitten)
    return crop

def berechneMittelwert(vektor):
    summe = [0,0,0]
    for pixel in vektor:
        summe += pixel
    return summe / len(vektor)

def berechneMittelwerte(vektoren):
    mittelwerte = []
    for vektor in vektoren:
        mittelwerte.append(berechneMittelwert(vektor))
    return np.asarray(mittelwerte)

def getSTDs(vektoren):
    STD = []
    for vektor in vektoren:
        STD.append(np.std(vektor,axis=0))
    return np.asarray(STD)

def erstelle_1D_histo_gewichtet(vektoren):
    _hist_vektor = []
    ANZAHLPIXEL = 320 * 258
    for vektor in vektoren:
        grau = rgb2gray(vektor)
        hist = np.histogram(grau, bins=16, range=(0, 256))[0]*ANZAHLPIXEL/len(vektor)
        _hist_vektor.append(hist)
    return np.asarray(_hist_vektor)


def erstelle_3d_histos_gewichtet(imgs,b):
    ANZAHLPIXEL = 320 * 258
    _hist = []

    for img in imgs:
        _hist.append(np.histogramdd(img, bins = [b,b,b], range=((0,256),(0,256),(0,256)))[0]*ANZAHLPIXEL/len(img))

    return np.asarray(_hist)

def erstelle_RGB_histos_gewichtet(vektoren,b):
    _hist_vektor = []
    ANZAHLPIXEL = 320 * 258

    for vektor in vektoren:
        histR = np.histogram(vektor[:,0], bins=b, range=(0, 256))[0]
        histG = np.histogram(vektor[:,1], bins=b, range=(0, 256))[0]
        histB = np.histogram(vektor[:,2], bins=b, range=(0, 256))[0]
        histR = histR * (ANZAHLPIXEL / len(vektor))
        histG = histG * (ANZAHLPIXEL / len(vektor))
        histB = histB * (ANZAHLPIXEL / len(vektor))
        _hist_vektor.append(np.hstack((histR, histG, histB)))
    return np.asarray(_hist_vektor)

def combineDisktiptor(dis1,dis2):
    dis_new = np.hstack((dis1,dis2))
    return np.asarray(dis_new)


def klassifiziereNN(trDesk, testDesk, trLabels):
    predictions = []
    deltaDesk = [0] * len(trDesk)

    for i in range(len(testDesk)):
        x = (trDesk - testDesk[i])
        for j in range(len(trDesk)):
            deltaDesk[j] = np.sqrt(np.sum((x[j, :]) ** 2))
        n = deltaDesk.index(min(deltaDesk))
        predictions.append(trLabels[n])
    return predictions

def ConfusionMatrix(prediction, validation, labelCount):
    '''
    :param prediction: the 1-Dimensional Array of predicted Labels
    :param validation: the 1-Dimensional Array of actual Labels
    :param labelCount: the numer of labels
    :return: a labelCount x labelCount ConfusionMatrix
    '''

    matrix = np.zeros((labelCount, labelCount), dtype=int)

    for i in range(len(prediction)):
        matrix[validation[i], prediction[i]] += 1
    return matrix

















trLabels = np.load('tr_Label.npy')
testLabels = np.load('test_Label.npy')
tr_vek = np.load("trImg_relevantOM.npy", allow_pickle=True)
test_vek = np.load("testImg_relevantOM.npy", allow_pickle=True)


#"""""
#trLabels,testLabels,trImgs,testImgs = ladeBilder(800,200)
#test_mask = createSMasks(testImgs)
#tr_mask = createSMasks(trImgs)
#trImg_relevant = erstelleVektorenOhneMinimum(trImgs,tr_mask)
#testImg_relevant = erstelleVektorenOhneMinimum(testImgs,test_mask)
#np.save("trImg_relevantOM.npy",trImg_relevant)
#np.save("testImg_relevantOM.npy",testImg_relevant)

#"""""
tr_STD = getSTDs(tr_vek)
test_STD = getSTDs(test_vek)
tr_mean = berechneMittelwerte(tr_vek)
test_mean = berechneMittelwerte(test_vek)
tr_dis = combineDisktiptor(tr_mean,tr_STD)
test_dis = combineDisktiptor(test_mean,test_STD)


predictions = klassifiziereNN(tr_dis, test_dis, trLabels)

evaluatedPredictions = predictions == testLabels #Berechnung der Trefferquote

correctPredictions = sum(evaluatedPredictions)

print("Trefferquote:", correctPredictions / len(testLabels) * 100, "%")

cMatrix = ConfusionMatrix(predictions, testLabels, 16) #Berechnung der Confusion Matrix

print(cMatrix)

