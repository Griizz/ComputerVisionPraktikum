import os
from keras.models import Sequential, Model
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten
from keras.optimizers import SGD
from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
BATCHSIZE = 8
LR = 0.01 / 16 * BATCHSIZE
FILEPATH = "./Best2.h5"

def SaveIMG(output,layer):
    for j in range(800):
        for i in range(32):
            img = output[j, :, :, i]
            plt.imsave("./Layer"+str(layer)+"/" + str(j) + "_" + str(i) + ".png", img)
    return print("fertig")


train_datagen = ImageDataGenerator(rescale=1. / 255, horizontal_flip=True)
val_datagen = ImageDataGenerator(rescale=1. / 255)
test_datagen = ImageDataGenerator(rescale=1. / 255)

train_generator = train_datagen.flow_from_directory(
    '../DataSetNew/Training',
    target_size=(256, 256),
    color_mode="rgb",
    class_mode="categorical",
    shuffle=True,
    batch_size=BATCHSIZE)

validation_generator = val_datagen.flow_from_directory(
    '../DataSetNew/Validation',
    target_size=(256, 256),
    color_mode="rgb",
    class_mode="categorical",
    batch_size=BATCHSIZE)

test_generator = test_datagen.flow_from_directory(
    '../DataSetNew/Test',
    target_size=(256, 256),
    color_mode="rgb",
    class_mode="categorical",
    batch_size=BATCHSIZE)

model = Sequential()

model.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1.1', input_shape=(256, 256, 3)))

layer_name = 'conv1.1'
intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)
intermediate_output = intermediate_layer_model.predict(test_generator)
SaveIMG(intermediate_output,1)

model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2.1'))

layer_name = 'conv2.1'
intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)
intermediate_output = intermediate_layer_model.predict(test_generator)
SaveIMG(intermediate_output,2)

model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3.1'))

layer_name = 'conv3.1'
intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)
intermediate_output = intermediate_layer_model.predict(test_generator)
SaveIMG(intermediate_output,3)

model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='conv4.1'))

layer_name = 'conv4.1'
intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)
intermediate_output = intermediate_layer_model.predict(test_generator)
SaveIMG(intermediate_output,4)

model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5.1'))

layer_name = 'conv5.1'
intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)
intermediate_output = intermediate_layer_model.predict(test_generator)
SaveIMG(intermediate_output,5)

model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(1024, (3, 3), activation='relu', padding='same', name='conv6.1'))

layer_name = 'conv6.1'
intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)
intermediate_output = intermediate_layer_model.predict(test_generator)
SaveIMG(intermediate_output,6)

model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(2048, (3, 3), activation='relu', padding='same', name='conv7.1'))

layer_name = 'conv7.1'
intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)
intermediate_output = intermediate_layer_model.predict(test_generator)
SaveIMG(intermediate_output,7)

model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(256, activation='relu', name='fc1', ))


model.add(Dense(16, activation='softmax'))  # FÃ¼r jedes Label ein output

modelCheckpoint = ModelCheckpoint(FILEPATH, monitor='val_loss', verbose=0, save_best_only=True,
                                  save_weights_only=False, mode='auto', period=1)

reduceLROnPlateau = ReduceLROnPlateau(monitor='val_loss', factor=0.25,
                              patience=5, min_lr=0.0005)

earlyStopping = EarlyStopping(patience=15, monitor='val_loss')

model.compile(loss='categorical_crossentropy',
              optimizer=SGD(lr=LR, momentum=0.9),
              metrics=['accuracy'])

model.fit_generator(train_generator,
                    steps_per_epoch=16 * 100 // BATCHSIZE,  # (Num_cat * pics_cat / batchSize)
                    epochs=10,
                    validation_data=validation_generator,
                    validation_steps=16 * 150 // BATCHSIZE,
                    callbacks=[modelCheckpoint, reduceLROnPlateau, earlyStopping])


